{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Loading and processing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "from retry_requests import retry\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score, KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Open-Meteo API client with cache and retry on error\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after = 3600)\n",
    "retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "# Make sure all required weather variables are listed here\n",
    "# The order of variables in hourly or daily is important to assign them correctly below\n",
    "url = \"https://historical-forecast-api.open-meteo.com/v1/forecast\"\n",
    "params = {\n",
    "    # melbourne coordinates\n",
    "\t\"latitude\": -37.814,\n",
    "\t\"longitude\": 144.9633,\n",
    "\t\"start_date\": \"2020-01-01\",\n",
    "\t\"end_date\": \"2024-12-25\",\n",
    "\t\"daily\": [\"weather_code\", \"temperature_2m_max\", \"temperature_2m_min\", \"sunrise\", \"sunset\", \"uv_index_max\", \"precipitation_sum\", \"wind_speed_10m_max\", \"wind_gusts_10m_max\"],\n",
    "\t\"timezone\": \"Australia/Sydney\"\n",
    "}\n",
    "responses = openmeteo.weather_api(url, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates -37.75째N 144.875째E\n",
      "Elevation 19.0 m asl\n",
      "Timezone b'Australia/Sydney' b'AEDT'\n",
      "Timezone difference to GMT+0 39600 s\n"
     ]
    }
   ],
   "source": [
    "# Process first location. Add a for-loop for multiple locations or weather models\n",
    "response = responses[0]\n",
    "print(f\"Coordinates {response.Latitude()}째N {response.Longitude()}째E\")\n",
    "print(f\"Elevation {response.Elevation()} m asl\")\n",
    "print(f\"Timezone {response.Timezone()} {response.TimezoneAbbreviation()}\")\n",
    "print(f\"Timezone difference to GMT+0 {response.UtcOffsetSeconds()} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process daily data. The order of variables needs to be the same as requested.\n",
    "daily = response.Daily()\n",
    "daily_weather_code = daily.Variables(0).ValuesAsNumpy()\n",
    "daily_temperature_2m_max = daily.Variables(1).ValuesAsNumpy()\n",
    "daily_temperature_2m_min = daily.Variables(2).ValuesAsNumpy()\n",
    "daily_sunrise = daily.Variables(3).ValuesAsNumpy()\n",
    "daily_sunset = daily.Variables(4).ValuesAsNumpy()\n",
    "daily_uv_index_max = daily.Variables(5).ValuesAsNumpy()\n",
    "daily_precipitation_sum = daily.Variables(6).ValuesAsNumpy()\n",
    "daily_wind_speed_10m_max = daily.Variables(7).ValuesAsNumpy()\n",
    "daily_wind_gusts_10m_max = daily.Variables(8).ValuesAsNumpy()\n",
    "\n",
    "daily_data = {\"date\": pd.date_range(\n",
    "\tstart = pd.to_datetime(daily.Time(), unit = \"s\", utc = True),\n",
    "\tend = pd.to_datetime(daily.TimeEnd(), unit = \"s\", utc = True),\n",
    "\tfreq = pd.Timedelta(seconds = daily.Interval()),\n",
    "\tinclusive = \"left\"\n",
    ")}\n",
    "\n",
    "daily_data[\"weather_code\"] = daily_weather_code\n",
    "daily_data[\"temperature_2m_max\"] = daily_temperature_2m_max\n",
    "daily_data[\"temperature_2m_min\"] = daily_temperature_2m_min\n",
    "daily_data[\"sunrise\"] = daily_sunrise\n",
    "daily_data[\"sunset\"] = daily_sunset\n",
    "daily_data[\"uv_index_max\"] = daily_uv_index_max\n",
    "daily_data[\"precipitation_sum\"] = daily_precipitation_sum\n",
    "daily_data[\"wind_speed_10m_max\"] = daily_wind_speed_10m_max\n",
    "daily_data[\"wind_gusts_10m_max\"] = daily_wind_gusts_10m_max\n",
    "daily_data[\"ave_temp\"] = (daily_temperature_2m_max + daily_temperature_2m_min)/2\n",
    "\n",
    "daily_dataframe = pd.DataFrame(data = daily_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input features: sunrise, sunset, uv, precipitation, wind speed and gust\n",
    "features = daily_dataframe[[\"sunrise\", \"sunset\", \"uv_index_max\", \"precipitation_sum\", \"wind_speed_10m_max\", \"wind_gusts_10m_max\", \"ave_temp\", \"weather_code\"]]\n",
    "\n",
    "# cannot use rows with missing features, so remove\n",
    "missing_rows = features[features.isna().any(axis=1)]\n",
    "\n",
    "# only train model using rows that contain all features\n",
    "valid_rows = features[features.notna().all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3a. Predicting temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cross validation to train, test and evaluate the model\n",
    "X = valid_rows[[\"uv_index_max\", \"precipitation_sum\", \"wind_speed_10m_max\", \"wind_gusts_10m_max\"]]\n",
    "Y = valid_rows[\"ave_temp\"]\n",
    "temp_models = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Mean Squared Error: 21.0693\n",
      "-0.0017689669822316123\n"
     ]
    }
   ],
   "source": [
    "# model 0: baseline model mean\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "mean_prediction = np.mean(Y_train)\n",
    "baseline_predictions = np.full_like(Y_test, mean_prediction, dtype=np.float64)\n",
    "mse = mean_squared_error(Y_test, baseline_predictions)\n",
    "r2 = r2_score(Y_test, baseline_predictions)\n",
    "\n",
    "temp_models[\"model0\"] = r2\n",
    "\n",
    "print(f\"Baseline Model Mean Squared Error: {mse:.4f}\")\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model0': -0.0017689669822316123, LinearRegression(): 0.4567053556442261}\n",
      "Cross-validation scores:  [0.42419428 0.5160076  0.4393962  0.44142914 0.46249956]\n",
      "Mean r2:  0.4567053556442261\n",
      "Standard deviation:  0.03206327842946231\n",
      "      Actual Values  Predicted Values\n",
      "448       16.845001          9.840088\n",
      "449       17.945000         16.849234\n",
      "450       17.645000         16.062347\n",
      "451       17.795000         17.189152\n",
      "452       16.744999         15.125054\n",
      "...             ...               ...\n",
      "1816      17.917000         20.931850\n",
      "1817      16.392000         20.946257\n",
      "1818      14.417000         19.867306\n",
      "1819      17.017000         20.413437\n",
      "1820      23.767000         20.278965\n",
      "\n",
      "[1373 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# model 1: simple linear regression\n",
    "model1 = LinearRegression()\n",
    "\n",
    "# Set up cross-validation (e.g., 5-fold cross-validation)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(model1, X, Y, cv=cv, scoring='r2')\n",
    "predictions = cross_val_predict(model1, X, Y, cv=cv)\n",
    "\n",
    "temp_models[model1] = float(np.mean(scores))\n",
    "print(temp_models)\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"Cross-validation scores: \", scores)\n",
    "print(\"Mean r2: \", np.mean(scores))\n",
    "print(\"Standard deviation: \", np.std(scores))\n",
    "\n",
    "results1 = pd.DataFrame({'Actual Values': Y, 'Predicted Values': predictions})\n",
    "print(results1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.38448389 0.4860208  0.44548204 0.41289272 0.425315  ]\n",
      "Mean r2:  0.4308388905807042\n",
      "Standard deviation:  0.03394356938248215\n",
      "      Actual Values  Predicted Values\n",
      "448       16.845001         10.613400\n",
      "449       17.945000         14.534430\n",
      "450       17.645000         14.763280\n",
      "451       17.795000         14.824360\n",
      "452       16.744999         15.301920\n",
      "...             ...               ...\n",
      "1816      17.917000         21.879400\n",
      "1817      16.392000         23.064911\n",
      "1818      14.417000         22.083200\n",
      "1819      17.017000         21.117751\n",
      "1820      23.767000         22.270420\n",
      "\n",
      "[1373 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# model 2: random forest regressor\n",
    "model2 = RandomForestRegressor()\n",
    "\n",
    "# Set up cross-validation (e.g., 5-fold cross-validation)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(model2, X, Y, cv=cv, scoring='r2')\n",
    "predictions = cross_val_predict(model2, X, Y, cv=cv)\n",
    "\n",
    "temp_models[model2] = float(np.mean(scores))\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"Cross-validation scores: \", scores)\n",
    "print(\"Mean r2: \", np.mean(scores))\n",
    "print(\"Standard deviation: \", np.std(scores))\n",
    "\n",
    "results2 = pd.DataFrame({'Actual Values': Y, 'Predicted Values': predictions})\n",
    "print(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.31978613 0.35005265 0.38050818 0.33395106 0.30518562]\n",
      "Mean r2:  0.337896728515625\n",
      "Standard deviation:  0.025988773187259527\n",
      "      Actual Values  Predicted Values\n",
      "448       16.845001         11.775000\n",
      "449       17.945000         14.079999\n",
      "450       17.645000         15.508799\n",
      "451       17.795000         13.508800\n",
      "452       16.744999         13.455000\n",
      "...             ...               ...\n",
      "1816      17.917000         18.622601\n",
      "1817      16.392000         22.682001\n",
      "1818      14.417000         22.257603\n",
      "1819      17.017000         18.786999\n",
      "1820      23.767000         21.271999\n",
      "\n",
      "[1373 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# model 3: KNN\n",
    "model3 = KNeighborsRegressor()\n",
    "\n",
    "# Set up cross-validation (e.g., 5-fold cross-validation)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(model3, X, Y, cv=cv, scoring='r2')\n",
    "predictions = cross_val_predict(model3, X, Y, cv=cv)\n",
    "\n",
    "temp_models[model3] = float(np.mean(scores))\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"Cross-validation scores: \", scores)\n",
    "print(\"Mean r2: \", np.mean(scores))\n",
    "print(\"Standard deviation: \", np.std(scores))\n",
    "\n",
    "results3 = pd.DataFrame({'Actual Values': Y, 'Predicted Values': predictions})\n",
    "print(results3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3b. Predicting weather codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use cross validation to train, test and evaluate the model\n",
    "X = valid_rows[[\"uv_index_max\", \"precipitation_sum\", \"wind_speed_10m_max\", \"wind_gusts_10m_max\"]]\n",
    "Y = valid_rows[\"weather_code\"]\n",
    "weather_models = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Accuracy: 0.4109\n"
     ]
    }
   ],
   "source": [
    "# model 0: Baseline Dummy Classifier\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "model0 = DummyClassifier() # uses the most frequent label\n",
    "model0.fit(X_train, Y_train)\n",
    "model0_predictions = model0.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, model0_predictions)\n",
    "\n",
    "weather_models[\"model0\"] = accuracy\n",
    "\n",
    "print(f\"Baseline Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores:  [0.57090909 0.59636364 0.56727273 0.5729927  0.60583942]\n",
      "Mean accuracy:  0.5826755142667551\n",
      "Standard deviation:  0.015449158401388653\n",
      "      Actual Values  Predicted Values\n",
      "448            55.0              80.0\n",
      "449            53.0              51.0\n",
      "450             3.0               3.0\n",
      "451            81.0              53.0\n",
      "452            51.0              51.0\n",
      "...             ...               ...\n",
      "1816            3.0               3.0\n",
      "1817           80.0              80.0\n",
      "1818           80.0              80.0\n",
      "1819            3.0               3.0\n",
      "1820            3.0               3.0\n",
      "\n",
      "[1373 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# model 1: Random Forest Classifier\n",
    "\n",
    "model1 = RandomForestClassifier()\n",
    "\n",
    "# Set up cross-validation (e.g., 5-fold cross-validation)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform cross-validation\n",
    "scores = cross_val_score(model1, X, Y, cv=cv, scoring='accuracy')\n",
    "predictions = cross_val_predict(model1, X, Y, cv=cv)\n",
    "\n",
    "weather_models[model1] = float(np.mean(scores))\n",
    "\n",
    "# Print cross-validation results\n",
    "print(\"Cross-validation scores: \", scores)\n",
    "print(\"Mean accuracy: \", np.mean(scores))\n",
    "print(\"Standard deviation: \", np.std(scores))\n",
    "\n",
    "results1 = pd.DataFrame({'Actual Values': Y, 'Predicted Values': predictions})\n",
    "print(results1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Determine best ML algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model0': -0.0017689669822316123, LinearRegression(): 0.4567053556442261, RandomForestRegressor(): 0.4308388905807042, KNeighborsRegressor(): 0.337896728515625}\n",
      "0.4567053556442261\n",
      "LinearRegression()\n",
      "{'model0': 0.4109090909090909, RandomForestClassifier(): 0.5826755142667551}\n",
      "0.5826755142667551\n",
      "RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "def get_dict_key(dictionary, value):\n",
    "    for key, val in dictionary.items():\n",
    "        if value == val:\n",
    "            return key\n",
    "\n",
    "# best temp model is one with highest r2 score (regression)\n",
    "best_temp_val = max(temp_models.values())\n",
    "best_temp_model = get_dict_key(temp_models, best_temp_val)\n",
    "print(best_temp_val)\n",
    "print(best_temp_model)\n",
    "\n",
    "# best weather code model is one with highest accuracy score (classifcation)\n",
    "best_weather_val = max(weather_models.values())\n",
    "best_weather_model = get_dict_key(weather_models, best_weather_val)\n",
    "print(best_weather_val)\n",
    "print(best_weather_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
